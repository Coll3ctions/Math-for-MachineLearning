### PS: This repository will keep growing as and when I will come across further resources and better sections.
### PS2: If you would like to suggest some resources to be added, please post it as an issue in the repo.

# Math for ML

In this repository, I will primarily discuss math for machine learning.

## My opinion on math requirements for ML

There are a lot of fancy courses out there that will teach you math like probability or statistics with R or Python or something else. I do not believe in these courses that they will teach you sufficient math to excel or even be good at ML.

The real math that you need ML is the theory. You can not use R or Python and their inbuilt functions to derive Logistic Regression's gradient descent equations. If you can't even derive Logistic Regression's gradient descent, I highly doubt you will be able to do any theoritical proof in the recent ML times.

In this repository, I will try to pin point free courses and some books related statistics/probability, calculus and optimization methods related to ML.

## Probability and Statistics
1. [Statistics 110-Probability](http://projects.iq.harvard.edu/stat110/youtube) by Harvard University: This is 'THE COURSE' in probability. If you finish this successfully, you won't need any further tutorials etc. for probability.
2. Probability [416.1x](https://www.edx.org/course/probability-distribution-models-purduex-416-2x-1) and [416.2x](https://www.edx.org/course/probability-distribution-models-purduex-416-2x-1) by Purdue University: These are good enough courses if you are not a math heavy person and want to start off with probability.
3. [Introduction to Probability - The Science of Uncertainty](https://www.edx.org/course/introduction-probability-science-mitx-6-041x-2#!) by MIT: This is one of my personal favorite courses. This is the middle ground between the above two courses. However, in order to be an expert in the content, you will need to do the content of the first course in the list by Harvard which is not covered in this list.


## Optimization Methods
While statistics and probability need no justification why these are neccessary for ML, a lot of people doubt the OM qualifications needed for an ML expert. OM is as important for ML as coding the model. You will be only able to appreciate 'closed-form' solutions in ML, if you understand OM.
1. [Optimization](http://nptel.ac.in/courses/111105039/) by IISc: While I haven't taken this course, the content is definetly amazing.
2. [Discrete Optimization](https://www.coursera.org/learn/discrete-optimization) by The University of Melbournel: This is an introductory course and if you have no idea or very little knowledge about optimization mathematics, start here.
3. [Optimization](http://www.cs.cmu.edu/~ggordon/10725-F12/schedule.html) by CMU: This is one course which wil also look at ML topics like gradient descent and coordinate descent from optimization perspective.


Will add more in coming days, specially books on Stats and content on OM and Linear Algebra. 'Star' the repo to get notifications.
